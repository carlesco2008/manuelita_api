################################################################################
#                                                                              #
#                   MANUELITA CHATBOT - MÃ“DULO 2: AGENTE EXPERTO                 #
#                                                                              #
#   VersiÃ³n: 5.0 "Espectacular"                                                #
#   Autor: [Tu Nombre/Equipo]                                                  #
#   Fecha: [Fecha Actual]                                                      #
#                                                                              #
#   PropÃ³sito: Un agente conversacional robusto que enruta inteligentemente    #
#              las consultas de los usuarios a la herramienta adecuada:        #
#              1. BÃºsqueda en base documental (RAG) para preguntas generales.  #
#              2. Consulta de datos estructurados para informaciÃ³n especÃ­fica. #
#                                                                              #
################################################################################

# ==============================================================================
# 0. LIBRERÃAS E IMPORTACIONES
# ==============================================================================
import gradio as gr
import os
import json
from dotenv import load_dotenv

# --- LangChain: El Ecosistema para construir con LLMs ---
# Componentes del RAG (Retrieval-Augmented Generation)
from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CrossEncoderReranker
from langchain_community.retrievers import BM25Retriever
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain_community.vectorstores import Chroma

# Modelos y Embeddings
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from langchain_google_genai import ChatGoogleGenerativeAI

# Componentes del Agente (El "cerebro" que elige herramientas)
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain.memory import ConversationBufferMemory
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import PromptTemplate

print("âœ… LibrerÃ­as importadas correctamente.")

# ==============================================================================
# 1. CONFIGURACIÃ“N CENTRALIZADA
# ==============================================================================
class Config:
    """
    Clase para centralizar todas las configuraciones del agente.
    Modificar estos valores es la forma mÃ¡s fÃ¡cil de experimentar.
    """
    # --- Modelos ---
    MODEL_LLM = "gemini-2.5-pro"
    MODEL_EMBEDDING = "sentence-transformers/all-MiniLM-L6-v2"
    MODEL_RERANKER = "BAAI/bge-reranker-base"
    
    # --- Rutas de Archivos ---
    PATH_KNOWLEDGE_BASE = "data/raw/"
    PATH_STRUCTURED_DATA = "datos_estructurados.json"
    
    # --- ParÃ¡metros del Retriever ---
    RETRIEVER_SEMANTIC_K = 7  # Documentos a obtener de la bÃºsqueda semÃ¡ntica
    RETRIEVER_KEYWORD_K = 7   # Documentos a obtener de la bÃºsqueda por palabras clave
    ENSEMBLE_WEIGHTS = [0.75, 0.25] # PonderaciÃ³n: 75% semÃ¡ntico, 25% palabra clave
    RERANKER_TOP_N = 3        # Documentos finales a enviar al LLM despuÃ©s de re-rankear

    # --- ParÃ¡metros del Agente ---
    AGENT_MAX_ITERATIONS = 5
    AGENT_TEMPERATURE = 0.0   # 0.0 para mÃ¡xima precisiÃ³n y consistencia

print("âœ… ConfiguraciÃ³n cargada.")

# ==============================================================================
# 2. DEFINICIÃ“N DE HERRAMIENTAS
# Un agente necesita herramientas para interactuar con el mundo.
# ==============================================================================

# ------------------------------------------------------------------------------
# HERRAMIENTA 1: BÃšSQUEDA EN DATOS ESTRUCTURADOS (JSON)
# ------------------------------------------------------------------------------
def buscar_datos_especificos(pregunta: str) -> str:
    """
    Busca informaciÃ³n puntual en un archivo JSON local.
    DiseÃ±ada para responder preguntas sobre datos de contacto, horarios y sedes.
    
    Args:
        pregunta (str): La pregunta del usuario.

    Returns:
        str: Una cadena en formato JSON con la informaciÃ³n encontrada o un
             mensaje de error.
    """
    print(f"DEBUG: [Herramienta 'Datos EspecÃ­ficos'] -> RecibiÃ³ la pregunta: '{pregunta}'")
    pregunta_lower = pregunta.lower()
    
    # --- Carga segura de los datos ---
    try:
        with open(Config.PATH_STRUCTURED_DATA, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        return json.dumps({"error": f"Archivo no encontrado en '{Config.PATH_STRUCTURED_DATA}'."})
    except json.JSONDecodeError:
        return json.dumps({"error": "El archivo de datos estructurados no es un JSON vÃ¡lido."})

    # --- LÃ³gica de enrutamiento por palabras clave ---
    if any(kw in pregunta_lower for kw in ["telÃ©fono", "contacto", "llamar", "correo", "email"]):
        return json.dumps(data.get("contacto", {"info": "No encontrÃ© detalles de contacto."}))
        
    if any(kw in pregunta_lower for kw in ["horario", "atenciÃ³n", "abren", "cierran"]):
        return json.dumps(data.get("horarios", {"info": "No encontrÃ© informaciÃ³n de horarios."}))
        
    if any(kw in pregunta_lower for kw in ["sedes", "direcciÃ³n", "ubicaciÃ³n", "oficina"]):
        return json.dumps(data.get("sedes_cali", [{"info": "No encontrÃ© informaciÃ³n sobre sedes."}]))
        
    if "nit" in pregunta_lower:
        return data.get("contacto", {}).get("nit", "No encontrÃ© el NIT en los datos.")
        
    return "Esta pregunta no parece ser sobre datos especÃ­ficos (contacto, horario, NIT). Intenta con la otra herramienta."

# ------------------------------------------------------------------------------
# HERRAMIENTA 2: BÃšSQUEDA DOCUMENTAL (SISTEMA RAG)
# ------------------------------------------------------------------------------
def crear_invocador_rag(retriever, llm):
    """
    Crea y devuelve una funciÃ³n que actÃºa como la herramienta RAG.
    Esto encapsula la cadena de recuperaciÃ³n para que sea fÃ¡cil de llamar.
    """
    rag_prompt = PromptTemplate.from_template(
        "Responde la pregunta del usuario de forma concisa y clara, basÃ¡ndote Ãºnicamente en el siguiente contexto:\n\n"
        "--- CONTEXTO ---\n{context}\n--- FIN CONTEXTO ---\n\n"
        "Pregunta: {input}"
    )
    
    document_chain = create_stuff_documents_chain(llm, rag_prompt)
    retrieval_chain = create_retrieval_chain(retriever, document_chain)
    
    def invocar_cadena_rag(pregunta: str) -> str:
        """
        Invoca la cadena RAG completa para responder preguntas generales.
        """
        print(f"DEBUG: [Herramienta 'RAG'] -> RecibiÃ³ la pregunta: '{pregunta}'")
        response = retrieval_chain.invoke({"input": pregunta})
        return response.get("answer", "No pude generar una respuesta a partir de los documentos.")
        
    return invocar_cadena_rag

print("âœ… Herramientas definidas.")

# ==============================================================================
# 3. LÃ“GICA DE INICIALIZACIÃ“N DEL AGENTE
# AquÃ­ se construye el "cerebro" del chatbot, paso a paso.
# ==============================================================================
def inicializar_agente_completo():
    """
    Orquesta toda la construcciÃ³n del agente: carga de datos, creaciÃ³n del
    retriever, instanciaciÃ³n del LLM y ensamblaje final del AgentExecutor.
    """
    try:
        # --- PASO 1: Cargar la API Key ---
        load_dotenv()
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("Error crÃ­tico: La variable de entorno GOOGLE_API_KEY no estÃ¡ configurada.")
        
        # --- PASO 2: Cargar y procesar la base de conocimiento para RAG ---
        print("INFO: Cargando documentos Markdown...")
        loader = DirectoryLoader(path=Config.PATH_KNOWLEDGE_BASE, glob="**/*.md", loader_cls=TextLoader, loader_kwargs={"encoding": "utf-8"})
        docs = loader.load()
        if not docs:
            raise FileNotFoundError(f"No se encontraron archivos .md en '{Config.PATH_KNOWLEDGE_BASE}'.")
        
        headers_to_split_on = [("#", "H1"), ("##", "H2"), ("###", "H3")]
        markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)
        splits = markdown_splitter.split_text("\n".join([doc.page_content for doc in docs]))
        print(f"INFO: {len(docs)} documentos -> {len(splits)} fragmentos (chunks).")
        
        # --- PASO 3: Construir el Retriever HÃ­brido con Re-ranking ---
        # Este es el corazÃ³n del sistema RAG. Combina lo mejor de dos mundos:
        # - BÃºsqueda SemÃ¡ntica (por significado) con ChromaDB y embeddings.
        # - BÃºsqueda por Palabras Clave (lexical) con BM25.
        # - Re-ranking para mejorar la precisiÃ³n de los resultados finales.
        print("INFO: Construyendo el retriever hÃ­brido...")
        embedding_model = HuggingFaceEmbeddings(model_name=Config.MODEL_EMBEDDING)
        vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)
        
        semantic_retriever = vectorstore.as_retriever(search_kwargs={"k": Config.RETRIEVER_SEMANTIC_K})
        keyword_retriever = BM25Retriever.from_documents(splits)
        keyword_retriever.k = Config.RETRIEVER_KEYWORD_K
        
        ensemble_retriever = EnsembleRetriever(
            retrievers=[semantic_retriever, keyword_retriever], 
            weights=Config.ENSEMBLE_WEIGHTS
        )
        
        reranker = CrossEncoderReranker(model=HuggingFaceCrossEncoder(model_name=Config.MODEL_RERANKER), top_n=Config.RERANKER_TOP_N)
        reranking_retriever = ContextualCompressionRetriever(base_compressor=reranker, base_retriever=ensemble_retriever)
        
        # --- PASO 4: Instanciar el LLM ---
        llm = ChatGoogleGenerativeAI(
            model=Config.MODEL_LLM,
            temperature=Config.AGENT_TEMPERATURE,
            google_api_key=api_key
        )
        
        # --- PASO 5: Ensamblar las herramientas para el Agente ---
        invocar_rag = crear_invocador_rag(reranking_retriever, llm)
        tools = [
            Tool(
                name="Consultar_Datos_Puntuales_Manuelita",
                func=buscar_datos_especificos,
                description=(
                    "INDISPENSABLE para obtener datos de contacto (telÃ©fono, correo, NIT), horarios de atenciÃ³n o direcciones/sedes. "
                    "Ãšsala si la pregunta contiene palabras como 'telÃ©fono', 'contacto', 'NIT', 'horario', 'direcciÃ³n', 'ubicaciÃ³n', 'sede', 'oficina'. "
                    "NO la uses para preguntas abiertas o generales."
                )
            ),
            Tool(
                name="Buscar_Informacion_General_Manuelita",
                func=invocar_rag,
                description=(
                    "HERRAMIENTA PRINCIPAL para todas las preguntas generales sobre la empresa Manuelita. "
                    "Ãšsala para temas como: historia de la empresa, productos, sostenibilidad, informes, etc. "
                    "Esta es tu opciÃ³n por defecto si la pregunta no es sobre datos de contacto especÃ­ficos."
                )
            ),
        ]
        
        # --- PASO 6: Crear el Prompt del Agente (las instrucciones del cerebro) ---
        agent_prompt_template = """
        Eres 'Manuelita Asistente', un chatbot experto en la empresa Manuelita. Tu Ãºnica tarea es analizar la pregunta del usuario y elegir la herramienta correcta para responderla. Sigue estas reglas al pie de la letra.

        **REGLAS DE DECISIÃ“N INFALIBLES:**
        1.  **Analiza la PREGUNTA ACTUAL:** Lee la pregunta del usuario cuidadosamente.
        2.  **Verifica si es sobre datos puntuales:** Si la pregunta contiene palabras clave como 'telÃ©fono', 'contacto', 'NIT', 'horario' o 'direcciÃ³n', DEBES usar la herramienta `Consultar_Datos_Puntuales_Manuelita`. SIN EXCEPCIONES.
        3.  **Para todo lo demÃ¡s, usa la bÃºsqueda general:** Si la regla 2 no se cumple, la pregunta es de conocimiento general. DEBES usar la herramienta `Buscar_Informacion_General_Manuelita`.
        4.  **Entrega la respuesta:** Una vez que la herramienta te dÃ© un resultado ('Observation'), tu Ãºnico trabajo es presentar esa informaciÃ³n al usuario de manera amable en la 'Final Answer'. NO uses otra herramienta despuÃ©s de obtener un resultado.

        **HERRAMIENTAS DISPONIBLES:**
        {tools}

        **FORMATO DE RESPUESTA OBLIGATORIO:**
        Thought: [Tu razonamiento paso a paso sobre quÃ© herramienta elegir segÃºn las reglas].
        Action: [El nombre EXACTO de la herramienta que elegiste].
        Action Input: [La pregunta original del usuario].
        Observation: [El resultado que te devuelve la herramienta].
        Thought: Tengo el resultado final. Ahora lo presentarÃ© al usuario.
        Final Answer: [La respuesta final para el usuario, en espaÃ±ol, clara y amable].

        --- Â¡EMPIEZA AHORA! ---
        **Historial de la conversaciÃ³n:**
        {chat_history}

        **Pregunta Actual:** {input}

        **Tu Proceso de Razonamiento:**
        {agent_scratchpad}
        """
        
        agent_prompt = PromptTemplate.from_template(agent_prompt_template).partial(
            tools="\n".join([f"{tool.name}: {tool.description}" for tool in tools]),
            tool_names=", ".join([tool.name for tool in tools]),
        )
        
        # --- PASO 7: Crear el Agente y el Executor ---
        agent = create_react_agent(llm, tools, agent_prompt)
        memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            memory=memory,
            verbose=True,
            handle_parsing_errors="Por favor, reformula tu pregunta. Tuve un problema para procesarla.",
            max_iterations=Config.AGENT_MAX_ITERATIONS
        )
        
        print("âœ… Agente 'Manuelita Asistente' inicializado y listo para operar.")
        return agent_executor, None

    except Exception as e:
        print(f"CRITICAL: Error durante la inicializaciÃ³n -> {e}")
        return None, e

# ==============================================================================
# 4. LÃ“GICA DE INTERFAZ Y EJECUCIÃ“N
# ==============================================================================
agent_executor, initialization_error = inicializar_agente_completo()

def get_agent_response(message, history):
    """
    FunciÃ³n de callback para Gradio. Gestiona la interacciÃ³n con el agente.
    """
    if initialization_error:
        return f"ğŸ”´ **Error CrÃ­tico de InicializaciÃ³n** ğŸ”´\n\nNo pude iniciar. RazÃ³n: {initialization_error}"
    if not agent_executor:
        return "ğŸ”´ **Error** ğŸ”´\n\nEl agente no estÃ¡ disponible. Revisa los logs del servidor."
        
    try:
        response = agent_executor.invoke({"input": message})
        return response["output"]
    except Exception as e:
        print(f"[ERROR EN EJECUCIÃ“N] -> {e}")
        return f"Lo siento, encontrÃ© un problema inesperado al procesar tu solicitud. Detalles: {e}"

def main():
    """
    FunciÃ³n principal que lanza la interfaz de Gradio.
    """
    print("ğŸš€ Lanzando la interfaz de Gradio...")
    
    # --- CreaciÃ³n de la Interfaz con Gradio ---
    demo = gr.ChatInterface(
        fn=get_agent_response,
        title="ğŸ¤– Manuelita Asistente Experto ğŸ¤–",
        description=(
            "Â¡Hola! Soy un asistente virtual especializado en Manuelita. "
            "Puedo buscar en nuestra base de conocimiento o consultar datos especÃ­ficos como telÃ©fonos y direcciones. Â¿En quÃ© te puedo ayudar?"
        ),
        examples=[
            ["Â¿QuÃ© tipos de uva de mesa cultivan?"],
            ["Â¿CuÃ¡l es el NIT de la empresa y el telÃ©fono de contacto?"],
            ["HÃ¡blame sobre la historia y fundaciÃ³n de Manuelita"],
            ["Â¿Tienen oficinas en Cali? Â¿CuÃ¡l es la direcciÃ³n?"],
        ],
        theme="soft",
        chatbot=gr.Chatbot(height=600, label="ConversaciÃ³n con Manuelita"),
        textbox=gr.Textbox(placeholder="Escribe tu pregunta aquÃ­...", label="Tu Consulta"),
        submit_btn="Enviar Consulta",
        clear_btn="Limpiar ConversaciÃ³n",
    )
    
    # --- Lanzamiento de la App ---
    # `share=True` crea un enlace pÃºblico temporal si lo necesitas.
    demo.launch()

# ==============================================================================
# PUNTO DE ENTRADA
# ==============================================================================
if __name__ == "__main__":
    # Este bloque asegura que el cÃ³digo solo se ejecute cuando el script
    # es llamado directamente.
    main()